### 进程代码实现

```python
from multiprocessing import Process
import time
# 多进程创建

def multipro(name):
    print('start :', name)
    time.sleep(2)
    print('end :', name)


if __name__ == '__main__':
    # 获取开始时间
    start_time = time.time()
    # 生成一个多线程的类
    # 参数target:函数 args:元组,函数传参
    p = Process(target=multipro, args=('xiaohua',))
    p1 = Process(target=multipro, args=('cis',))
    p2 = Process(target=multipro, args=('xhisd',))
    # 线程开始
    p.start()
    p1.start()
    p2.start()
    # 等待线程结束 (阻塞)
    p.join()
    p1.join()
    p2.join()

    # 打印程序运行时间
    print(time.time()-start_time)
    # 2.1795127391815186
```



### 线程代码实现

```python
from threading import Thread
import time

# 线程创建

def threadDemo(name):
    print('start :', name)
    time.sleep(2)
    print('end :', name)


if __name__ == '__main__':
    start_time = time.time()
	# 创建一个线程类
    # 参数target:函数 args:元组,函数传参
    t = Thread(target=threadDemo, args=('xiaohua',))
    t1 = Thread(target=threadDemo, args=('kjljkf',))
    t2 = Thread(target=threadDemo, args=('fsdf',))

    # 线程开始
    t.start()
    t1.start()
    t2.start()
    # 等待线程结束 (阻塞)
    t.join()
    t1.join()
    t2.join()

    # 打印程序运行时间
    print(time.time() - start_time)
    # 2.0028369426727295
    # 线程的运行时间比进程的要短,是因为1.进程里都有一个线程2.进程发生切换创建耗时

```



### 进程池

引入进程池的概念为了解决:

1. 每个任务一个进程,100个任务时,限制进程的数量
2. 如果任务过多,频繁的创建和销毁进程,影响性能

```python
from multiprocessing import Pool
import time

# 进程池的使用
def multipro(name):
    print('start :', name)
    time.sleep(1)
    print('end :', name)
    time.sleep(0.5)

if __name__ == '__main__':
    # 用法
    # 创建限制同时进行的进程为3
    # 并且进程池是复用的
    pool = Pool(processes=3)
    names = ['aa', 'bb', 'cc', 'dd', 'ff']

    for name in names:
        # 这里会将所有的name放入pool里面
        # 参数target:函数 args:元组,函数传参
        pool.apply_async(func=multipro, args=(name,))
        # res = res.get 获取返回值
    # 当用完pool进程池之后,需要关闭
    pool.close()
    # 关闭后不能再使用进程池
    # pool.apply_async(func=multipro, args=('name',))
    # 打印错误 : ValueError: Pool not running

    # 关闭后,需要等待所有的进程执行结束
    pool.join()
```



自行了解:

1. 进程池中的信息传递 	Manager().Queue
2. 进程池中的返回值         res.get获取 在for循环pool.apply_async之后



### 协程

```python
'''
协程相关内容
gevent : 速率比较快
1. 不需要多启动进程或者线程
2. 进程和线程的切换比较耗时
3. 协程不需要cup的切换
4. 使用的是 yeild 实现方式

yeild的两种方式:
1. yeild ***
2. *** = yeild  和send一起使用
'''

import gevent
from gevent import monkey
monkey.patch_all()
# 放在其他的import之后会有警告
import time
import requests

# 猴子补丁,为了实现并发效果
'''
requests分为发送请求和接受返回数据两部分
中间有个时间间隔
目的是为了给requests请求过程中间加一个yeild

'''

def multipro(name):
    '''
    如果程序报错,可尝试在requests里加参数:verity=False
    若requests的请求过多,会占用大量资源
    :param name:协程
    :return:
    '''
    print('start :', name)
    response = requests.get('http://www.baidu.com')
    print('end :', name)


if __name__ == '__main__':
    start_time = time.time()
    p = gevent.spawn(multipro, 'xiaohua')
    p1 = gevent.spawn(multipro, 'sss')
    p2 = gevent.spawn(multipro, 'xiddddaohua')
    p3 = gevent.spawn(multipro, 'xiaohffua')
    p4 = gevent.spawn(multipro, 'gggg')

    gevent.joinall([p, p1, p2, p3, p4])
    print(time.time() - start_time)
    # 1.512552261352539

# for i in range(27, 1000):
    # print('p'+str(i)+"= gevent.spawn(multipro, 'xiaohua')")
    # print('p' + str(i), end=', ')


```



### 进程实现代理获取验证

```python
import requests
from lxml import etree
import time
from multiprocessing import Pool


# 根据传参url,获取当页所有的ip和端口号
def get_free_url(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'
    }
    response = requests.get(url, headers=headers)
    # with open('xici.html', 'wb') as f:
    #     f.write(response.content)
    res = etree.HTML(response.text)
    # 这是拷贝过来的xpath里的tbody层是获取不到的
    # //*[@id="ip_list"]/tbody/tr[2]/td[2]
    num_ip = res.xpath('//*[@id="main"]/div/div[1]/table/tr/td[1]')
    num_port = res.xpath('//*[@id="main"]/div/div[1]/table/tr/td[2]')
    # print(num_ip, num_port)
    # print(len(num_ip))
    ip_list = []
    for i in range(1, len(num_ip)):
        proxyIp = num_ip[i].text + ':' + num_port[i].text
        # print(proxyIp)
        ip_list.append(proxyIp)
    return ip_list


# 验证ip是否可用
def test_ip(ip):
    time.sleep(0.5)
    print('验证ip:', ip)
    # url = 'http://httpbin.org/get'
    url = 'http://www.baidu.com'
    proxy = {
        # 'http://180.122.151.35:49645'
        'http': 'http://' + ip,
        'https': 'https://' + ip,
    }
    try:
        # verity=False
        response = requests.get(url, proxies=proxy,timeout=5)
        print(response.status_code)
        # # print(response.text)
        # res = json.loads(response.text)
        # ip_ele = res['origin']
        print('ip可用:', ip)
        return ip
    except:
        print('ip不可用')

# 进程池函数
def processPool():
    # 初始化存放列表
    useful_ip = []
    # 循环遍历页数
    for i in range(2, 3):
        print('第{}页'.format(i))
        url = 'http://www.66ip.cn/{}.html'.format(i)
        # 调用获取ip函数
        ip_list = get_free_url(url)

        # 创建线程池
        pool = Pool(processes=5)
        for ip in ip_list:
            # 进程池启动将所有ip存入进程池
            res = pool.apply_async(func=test_ip, args=(ip,))
            # 将所有ip存入列表
            useful_ip.append(res)
        pool.close()
        pool.join()
    # 得到的是线程池返回值,拿值需要遍历用get()
    # print(useful_ip)
    # <multiprocessing.pool.ApplyResult object at 0x037E6A78>
    res_list = []
    for useIp in useful_ip:
        if useIp.get() != None:
            # 将进程池返回值用get()方式取出
            res_list.append(useIp.get())
    return  res_list

if __name__ == '__main__':
    '''
        程序入口
        验证 66代理 网站的可用ip
    '''
    start_time = time.time()
    res_list = processPool()
    print('可用ip列表:\n', res_list)
    print(time.time() - start_time)
# ['210.48.204.134:59916', '103.9.227.210:53281', '41.242.57.34:38783', '95.142.219.181:56379', '118.174.196.130:8080', '157.245.205.81:8080', '95.9.150.33:47923', '157.100.58.97:999', '103.93.90.246:23500']

```



调试:

1. 看错误的输出语句(在信息的最后一句话)
2. 从下向上找,找到自己写的文件信息
3. 百度解决